<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="https://victorangeloblancada.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://victorangeloblancada.github.io/" rel="alternate" type="text/html" /><updated>2025-02-28T22:42:33+08:00</updated><id>https://victorangeloblancada.github.io/feed.xml</id><title type="html">Victor Angelo Blancada</title><subtitle>Victor Angelo Blancada is a data scientist, AI developer, and strategy consultant with proven experience in improving operational efficiency through predictive modeling and AI-powered automation.</subtitle><entry><title type="html">Dissecting a Power BI Dashboard</title><link href="https://victorangeloblancada.github.io/blog/2024/12/13/dissect-pbix.html" rel="alternate" type="text/html" title="Dissecting a Power BI Dashboard" /><published>2024-12-13T00:00:00+08:00</published><updated>2024-12-13T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2024/12/13/dissect-pbix</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2024/12/13/dissect-pbix.html"><![CDATA[<p>In this article, we will thoroughly explore the structure and contents of a Power BI dashboard (PBIX) file. Like most Microsoft Office file formats, a PBIX file is actually a zipped folder containing various directories and files which work together to form the dashboard we see. Understanding the underlying architecture of a Power BI report is crucial for both users and developers, as it enables a deeper appreciation of how data is structured, processed, and displayed.</p>

<p>This guide will break down the various directories and files found inside the zipped folder of a PBIX file, explain their purpose, and show how these elements work together to create the final dashboard. We will also delve into the core <code class="language-plaintext highlighter-rouge">Layout</code> file, which plays a key role in defining how data is translated into charts, tables, and other visualizations within the dashboard.</p>

<h2 id="overview-of-a-power-bi-report-package-structure">Overview of a Power BI Report Package Structure</h2>

<p>A PBIX file is typically organized in a package with a clearly defined directory structure. This structure can be exposed by changing the file extension from PBIX to ZIP, then unzipping the resulting zipped folder to reveal its contents.</p>

<p>Each folder and file within this structure serves a specific purpose in making the dashboard work the way it does. Below is an overview of the key directories and files in the report package:</p>

<p><em>rels<br />
|</em> .rels<br />
docProps<br />
|_ custom.xml<br />
Report<br />
|_ Layout<br />
|_ StaticResources\SharedResources\BaseThemes<br />
   |_ CY24SU08.json<br />
[Content_Types].xml<br />
DataModel<br />
DiagramLayout<br />
Metadata<br />
SecurityBindings<br />
Settings<br />
Version</p>

<p>Each of these components plays a vital role in ensuring that the report is displayed and interacts as intended. We will break down each section to understand what it contains and how it contributes to the functionality of the dashboard.</p>

<h3 id="the_relsdirectory">The <code class="language-plaintext highlighter-rouge">_rels</code> Directory</h3>

<p>The <code class="language-plaintext highlighter-rouge">_rels</code> directory is one of the most critical directories in the Power BI report package. It contains the <code class="language-plaintext highlighter-rouge">.rels</code> file, which manages the relationships between different parts of the report.</p>

<p>The <code class="language-plaintext highlighter-rouge">.rels</code> file stores the relationships between various elements of the report. For example, it could define how the layout file is connected to the static resources or how the report interacts with external data models. The <code class="language-plaintext highlighter-rouge">.rels</code> file ensures that when the report is opened, the application knows how to load and render the different parts of the report package correctly.</p>

<h3 id="thedocpropsdirectory">The <code class="language-plaintext highlighter-rouge">docProps</code> Directory</h3>

<p>The <code class="language-plaintext highlighter-rouge">docProps</code> directory contains metadata files that provide additional information about the report. Metadata is essential for defining the context and properties of the report, which can be helpful for tracking and reporting purposes.</p>

<p>The <code class="language-plaintext highlighter-rouge">custom.xml</code> file stores user-defined properties, such as the author of the report, version number, or other custom attributes relevant to the report. For example, it could store details about the report’s creation date, the business unit it pertains to, or custom fields that help categorize and filter the report.</p>

<h3 id="thereportdirectory">The <code class="language-plaintext highlighter-rouge">Report</code> Directory</h3>

<p>The <code class="language-plaintext highlighter-rouge">Report</code> directory is where the majority of the report’s configuration and layout components are found. It contains the layout file, static resources, and any base themes that are used to define the visual look and feel of the report. These elements are key in defining how the data is visually presented.</p>

<h4 id="layout">Layout</h4>

<p>The layout file is the core of the report. It defines the visual structure of the report, specifying how the data will be displayed in charts, tables, and other visual elements. The layout file determines the positions of various components on the report canvas and ensures that the visual elements are placed and sized correctly.</p>

<p>As an example, the <code class="language-plaintext highlighter-rouge">Layout</code> file may define the report’s main visual container, which could hold a chart, such as a column chart. The chart may be configured to display data from a table named <code class="language-plaintext highlighter-rouge">Table1</code>, and the layout also specifies how the data is grouped by different time periods (such as year, quarter, month, and day). It also defines how specific measures, like the quantity of items sold, are aggregated and visualized in the chart.</p>

<p>The layout file also specifies the data projections (i.e., the data elements to be displayed in the chart), the filters that should be applied to restrict the data, and how different data roles (such as categories, series, and rows) are mapped to the visual components.</p>

<h4 id="staticresourcessharedresourcesbasethemes">StaticResources\SharedResources\BaseThemes</h4>

<p>The <code class="language-plaintext highlighter-rouge">CY24SU08.json</code> file defines the visual theme for the report. Themes are used to maintain consistency in design across different reports and dashboards. This JSON file stores information about color schemes, fonts, and other stylistic choices that apply throughout the report. By using a theme like <code class="language-plaintext highlighter-rouge">CY24SU08.json</code>, the report ensures that all visual elements are cohesive and adhere to a specific design aesthetic, whether for brand consistency or user experience.</p>

<h3 id="other-key-files-in-the-report-package">Other Key Files in the Report Package</h3>

<p>In addition to the layout and theme resources, there are several other important files that contribute to the functionality of the report.</p>

<h3 id="content_typesxml">[Content_Types].xml</h3>

<p>The <code class="language-plaintext highlighter-rouge">[Content_Types].xml</code> file is essential for defining the MIME types for the various parts of the report package. It helps the report-rendering system determine how to process different file types within the package, such as XML files, images, or JSON files. This file serves as a map for the content and ensures that each component is handled correctly.</p>

<h3 id="datamodel">DataModel</h3>

<p>The <code class="language-plaintext highlighter-rouge">DataModel</code> binary contains the underlying schema and data definitions that drive the report. It includes details such as tables, columns, and relationships between different datasets. This folder is vital because it defines the data structure that feeds into the visual components, allowing the dashboard to present relevant and accurate information. This file usually cannot be read because its encoding is not supported by most text editors.</p>

<h3 id="diagramlayout">DiagramLayout</h3>

<p>The <code class="language-plaintext highlighter-rouge">DiagramLayout</code> directory may contain files that define additional visual elements, such as diagrams, flowcharts, or other graphical representations that complement the report’s main data visuals. While the core report may focus on charts and tables, diagram layouts can help explain complex data relationships or workflows visually.</p>

<h3 id="metadata">Metadata</h3>

<p>Metadata files store information about the report itself, such as the author, version history, creation date, and other contextual information. These files are crucial for tracking changes and updates to the report, ensuring that the correct version is always used and providing information about the report’s lifecycle.</p>

<h3 id="securitybindings">SecurityBindings</h3>

<p>The <code class="language-plaintext highlighter-rouge">SecurityBindings</code> binary handles the security aspects of the report, ensuring that sensitive data is protected. It defines access control and permissions, specifying which users or groups can view certain sections or interact with specific data points within the report. This is particularly important for reports containing sensitive or confidential information. This file usually cannot be read because its encoding is not supported by most text editors.</p>

<h3 id="settings">Settings</h3>

<p>The <code class="language-plaintext highlighter-rouge">Settings</code> directory contains configuration files that manage preferences or environment-specific settings for the report. These settings ensure that the report behaves as expected across different platforms and environments, whether it’s running locally or being accessed via a web service.</p>

<h3 id="version">Version</h3>

<p>The <code class="language-plaintext highlighter-rouge">Version</code> file indicates the current version of the report or report package. This is important for version control, ensuring that users are working with the most up-to-date version of the report and helping to prevent the use of outdated or deprecated files.</p>

<h3 id="parsing-and-interpreting-the-layout-file">Parsing and Interpreting the Layout File</h3>

<p>Let’s take a closer look at the <code class="language-plaintext highlighter-rouge">Layout</code> file, which is at the heart of how the report’s visual elements are configured. The layout file is a configuration file, often in JSON format, that dictates the presentation and interaction of the data in the report.</p>

<h3 id="key-aspects-of-the-layout-file">Key Aspects of the Layout File</h3>

<ol>
  <li><strong>Visual Containers</strong>: The layout file defines a visual container (e.g., a chart or table) that holds the report’s data. For example, in this case, the container holds a column chart, and the file specifies its position, size, and dimensions on the report canvas.</li>
  <li><strong>Projections and Querying</strong>: The <code class="language-plaintext highlighter-rouge">projections</code> section in the layout file specifies which data elements should be displayed. This includes categories, series, and rows, as well as aggregation functions (e.g., sum, count). This section ensures that the right data is selected and formatted for visualization.</li>
  <li><strong>Filters</strong>: Filters are used to limit which data points are shown in the report. These filters can be based on specific criteria (e.g., dates, categories, or regions) to ensure that the report displays only relevant information.</li>
  <li><strong>Data Role Mapping</strong>: The <code class="language-plaintext highlighter-rouge">Layout</code> file maps the data roles to the visual components. For instance, categories might be mapped to the x-axis, while series could be used for color-coding the data. These mappings help translate raw data into meaningful visualizations.</li>
  <li><strong>Execution Metrics</strong>: The layout file may also include execution metrics that track how efficiently the report is rendering, especially when dealing with large datasets. This ensures that the report performs well and loads quickly.</li>
</ol>

<h2 id="summary">Summary</h2>

<p>Understanding the inner workings of a Power BI report requires more than just familiarity with the visual components. The underlying structure, including the directories and files that make up the report package, plays a crucial role in ensuring that the report functions correctly. Each file, from the layout to metadata and security settings, contributes to the overall experience of the report, ensuring that the data is presented clearly, accurately, and securely.</p>

<p>The <code class="language-plaintext highlighter-rouge">Layout</code> file, in particular, is essential for defining how data is visualized. By carefully structuring the report’s visuals and ensuring that the data is aggregated and displayed correctly, the layout file is a key component in transforming raw data into actionable insights. When working with or developing Power BI reports, understanding these elements will help you navigate and optimize the report for both users and analysts alike.</p>]]></content><author><name></name></author><category term="blog" /><category term="power bi" /><category term="dashboard" /><category term="microsoft" /><summary type="html"><![CDATA[PBIX files are zipped folders and examining their contents can shed light on how Power BI translates data into visualizations.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/dissect.webp" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/dissect.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The Negative Effect of Pruning Large Language Models on Finetuning</title><link href="https://victorangeloblancada.github.io/blog/2024/05/31/llm-pruning-finetuning.html" rel="alternate" type="text/html" title="The Negative Effect of Pruning Large Language Models on Finetuning" /><published>2024-05-31T00:00:00+08:00</published><updated>2024-05-31T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2024/05/31/llm-pruning-finetuning</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2024/05/31/llm-pruning-finetuning.html"><![CDATA[<p>Large language models (LLMs) such as Llama and Falcon often serve as foundational models, the bedrock upon which more specialized AI applications are built through finetuning. However, the computational demands of these models pose a significant challenge for both inference and finetuning. Techniques in optimizing neural networks, particularly pruning, may offer a solution by reducing the number of model parameters for more efficient inference without a consequent large negative effect on accuracy. However, while pruning reduces computational requirements for inference, it also reduces a model’s ability to be finetuned, as will be explained in this article. This poses a challenge for organizations wishing to leverage AI language models for specialized use.</p>

<p>Pruning aims to make neural networks more efficient by removing unnecessary connections within the model. Common pruning methods include:</p>

<ul>
  <li>Magnitude-based pruning: Eliminates connections with weights below a certain threshold.</li>
  <li>Structured pruning: Removes entire groups of neurons or connections.</li>
</ul>

<p>Pruning is effective in reducing the size of different models, but given the recent gold rush to deploy language models, it is important to look at its effect on these language models.</p>

<p>For large language models like GPT, Llama, and Falcon, pruning offers inference efficiency gains. However, pruning may potentially compromise adaptability during fine-tuning. Redundant neurons are often useful for encoding new information from finetuning, but they are often removed during the pruning process, thus hindering the model’s capacity to learn new information.</p>

<p>To illustrate, consider a language model pre-trained on a diverse corpus of text. The redundancies in the model allow it to store the same information across different layers and weights. During finetuning for a sentiment analysis, the model may learn to differentiate words or phrases with the same denotation (explicit meaning) but different connotation (culturally-specific nuance) based on the provided training data and can use the neural network’s redundancies to store these differences. However, if these redundancies had been pruned, the model loses the flexibility to encode these more nuanced relationships, leading to suboptimal performance.</p>

<p>Organizations therefore face a strategic decision regarding pruning:</p>

<ul>
  <li>Resource Constraints: Pruned FLMs offer efficiency benefits, suitable for resource-constrained environments where computational resources are limited. Despite potential limitations in fine-tuning, efficiency gains may outweigh adaptability concerns.</li>
  <li>Task Complexity: For intricate tasks demanding precise adaptation, unpruned language models with full learning capacity are desired. These models will excel in capturing complex relationships from new information, essential for nuanced tasks like legal document analysis.</li>
</ul>

<p>Pruning large language models presents a trade-off, optimizing efficiency at the expense of adaptability later on. Striking the right balance is paramount as organizations seek to leverage AI in an evolving business environment.</p>

<p>My advice would be to use the largest language model which an organization’s hardware permits as a foundational model for finetuning, then only start pruning the model after finetuning is finished.</p>

<p>By understanding the nuances of pruning and its implications for fine-tuning, businesses can make informed decisions, harnessing the power of language models while achieving desired outcomes in specialized domains.</p>]]></content><author><name></name></author><category term="blog" /><category term="ai" /><category term="artificial intelligence" /><category term="llm" /><category term="large language model" /><category term="pruning" /><category term="fine-tuning" /><summary type="html"><![CDATA[Pruning large language models make them easier to deploy but also make them harder to finetune for the specific tasks organizations may want them to perform.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/pruning-networks.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/pruning-networks.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Fuzzy Matching in Python</title><link href="https://victorangeloblancada.github.io/blog/2024/03/02/fuzzy-matching-in-python.html" rel="alternate" type="text/html" title="Fuzzy Matching in Python" /><published>2024-03-02T00:00:00+08:00</published><updated>2024-03-02T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2024/03/02/fuzzy-matching-in-python</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2024/03/02/fuzzy-matching-in-python.html"><![CDATA[<p><em>This is part of a series of short blog posts about automating repetitive work using Python.</em></p>

<p>This is how to perform partial matching or fuzzy matching in Python using <a href="https://github.com/seatgeek/thefuzz">TheFuzz library</a>. This is useful for scenarios such as matching addresses written in different formats (e.g., New York vs NewYork vs New York City) or fixing typos in categorical data (e.g., Brusels can be matched to Brussels).</p>

<p>Start by importing process from TheFuzz:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import fuzzy matching libraries
</span><span class="kn">from</span> <span class="nn">thefuzz</span> <span class="kn">import</span> <span class="n">process</span>
</code></pre></div></div>

<p>Assuming you have two Pandas dataframes, df_1 and df_2, which you want to join on col_1 and col_2, respectively, you can run the following code to show matches from df_2 in df_1:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create column of match result object. The extractOne function only returns the best match.
</span><span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Result'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">[</span><span class="n">col_1</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">process</span><span class="p">.</span><span class="n">extractOne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df_2</span><span class="p">[</span><span class="n">col_2</span><span class="p">]))</span>
<span class="c1"># Extract fuzzy matching string from result
</span><span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Result'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># Extract fuzzy matching score
</span><span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Result'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div></div>

<p>Here is the code as one big block:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import fuzzy matching libraries
</span><span class="kn">from</span> <span class="nn">thefuzz</span> <span class="kn">import</span> <span class="n">process</span>

<span class="c1"># Load the two dataframes you want to fuzzy match
</span><span class="n">df_1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'file_1.xlsx'</span><span class="p">)</span>
<span class="n">df_2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'file_2.xlsx'</span><span class="p">)</span>

<span class="c1"># The column name to match in df_1
</span><span class="n">col_1</span> <span class="o">=</span> <span class="s">'column'</span>
<span class="c1"># The column name to match in df_2
</span><span class="n">col_2</span> <span class="o">=</span> <span class="s">'column'</span>

<span class="c1"># Create column of match result object. The extractOne function only returns the best match.
</span><span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Result'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">[</span><span class="n">col_1</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">process</span><span class="p">.</span><span class="n">extractOne</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df_2</span><span class="p">[</span><span class="n">col_2</span><span class="p">]))</span>
<span class="c1"># Extract fuzzy matching string from result
</span><span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Result'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># Extract fuzzy matching score
</span><span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">[</span><span class="s">'Fuzzy Match Result'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="blog" /><category term="python" /><category term="data science" /><category term="data analysis" /><summary type="html"><![CDATA[How to perform partial or fuzzy matching in Python.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/fuzzy.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/fuzzy.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">What The Media Gets Wrong About ChatGPT</title><link href="https://victorangeloblancada.github.io/blog/2023/02/09/media-wrong-chatgpt.html" rel="alternate" type="text/html" title="What The Media Gets Wrong About ChatGPT" /><published>2023-02-09T00:00:00+08:00</published><updated>2023-02-09T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2023/02/09/media-wrong-chatgpt</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2023/02/09/media-wrong-chatgpt.html"><![CDATA[<p>Like most people, I enjoyed testing OpenAI’s ChatGPT and I was also excited to see what Google’s Bard was capable of. Unlike most people though, I have been following the development of text generation from Markov chains to Andrej Karpathy’s blog post on <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>. This has allowed me to see past certain misconceptions in the media about both ChatGPT and Bard.</p>

<h2 id="chatgpt-is-not-a-search-engine-replacement-yet">ChatGPT Is Not a Search Engine Replacement (Yet)</h2>

<p>ChatGPT is a large language model (LLM) created by OpenAI to provide conversational AI services. It was specifically developed to push the envelope of what is possible with generative natural language processing (NLP) through methods such as generative pre-trained transformers (GPT) and reinforcement learning with human feedback (RLHF). Its positioning as a demonstration of cutting-edge NLP capabilities is apparent in OpenAI’s decision to restrict the model’s access to the Internet. ChatGPT instead extrapolates from its finite but admitted very large training data which was limited to only 2021; so if you ask it about events in 2023, it simply extrapolates believable responses based on its 2021 data. This is something ChatGPT does incredibly well: when asked about the version of PyTorch (a widely-used machine learning framework), it gives a response that is reasonably (and believably) close.</p>

<p>Therein lies the rub. The reason ChatGPT’s responses read as very believable because it was designed to maximize its chances of passing the Turing test, i.e. roleplay as a believable human, rather than be correct all the time. Users without an understanding of what ChatGPT was designed for and how it was trained have arrived at the incorrect impression that it can serve as a replacement for search engines. ChatGPT was never designed for that use case and it is, at the very least, unfair to its developers to measure its capabilities as a search engine and, at the very worst, irresponsible and dangerous to use its outputs without first doing some fact-checking.</p>

<p>Why then is Microsoft touting ChatGPT-powered capabilities in Bing? The short answer (believable but not 100% accurate) is that search engines represent an established business model where advertisers would happily pay top dollar to improve brands’ positioning on search results. The longer and more accurate answer is that Microsoft is in fact incorporating ChatGPT into most of its products, including Microsoft Word and Microsoft Teams. The media has simply latched onto the story of ChatGPT-powered Bing because:</p>

<ol>
  <li>it represents a bold encroachment by Microsoft upon the search engine space which for decades has been Google’s turf; and</li>
  <li>Bing is a free service unlike licensed software such as Microsoft Office, making it very easy for users to test it.</li>
</ol>

<p>On a side note, OpenAI is reportedly working on a the next version of its GPT-powered LLM. With Microsoft’s significant investment in the company, it is not unlikely that this new version will be designed specifically for use as part of the Bing search engine.</p>

<p>That said, Google’s release of Bard in reaction to ChatGPT has (perhaps unfairly) been labeled by the press as underwhelming. Any product that is shoehorned into a use case it wasn’t initially designed for (e.g., an LLM being used as a search engine) in reaction to another existing product is unlikely to succeed. The media’s complaints about bard revolve around two main things:</p>

<ol>
  <li>Bard allegedly provides false information; and</li>
  <li>Bard’s user experience is supposedly boring</li>
</ol>

<p>The counter-argument to the first point is the same one against the use of ChatGPT as a search engine. At best these LLMs need to balance maximizing accuracy and believability and, at worst, may not emphasize accuracy at all. ChatGPT is supposedly version 3.5 of OpenAI’s GPT-powered LLMs (after GPT, GPT-2, and GPT-3) and has been fine-tuned based on years of human feedback. It is understandable that Bard will need time to reach that level of refinement.</p>

<p>As for the second point, user experience is another thing that improves over time as companies get more feedback from users. It can be argued that among the many breakthroughs of ChatGPT was finding a user-friendly interface for testers and eventual users to enjoy using it. Previous versions of OpenAI’s GPT-powered LLMs (several of which I also tested and even deployed on my own machine) were designed to complete user provided prompts instead of replying as a chatbot. By framing the ChatGPT as a chatbot instead of a text-generation model, OpenAI succeeded in finding a user experience that delighted users instead.</p>

<hr />

<h2 id="ps-openai-is-not-a-small-startup">P.S.: OpenAI Is Not a “Small Startup”</h2>

<p>There have also been numerous stories circulating presenting OpenAI as a tiny startup that beat the behemoth that is Google in some sort of David versus Goliath tale. While this certainly makes a clickbaity (and believable) headline, this isn’t 100% true either.</p>

<p>While OpenAI was originally a non-profit with a small team, it boasts both:</p>

<ol>
  <li>financial backing (at various times) from giants such as Microsoft, Amazon Web Services, Peter Thiel, and Elon Musk; and</li>
  <li>a highly-regarded and well-compensated research team including OpenAI co-founder and former Google machine learning expert Ilya Sutskever.</li>
</ol>

<p>In an extremely technical field such as machine learning, team size doesn’t affect results as much as individuals’ expertise. It is therefore come as no surprise that the OpenAI team can produce such impressive models despite being depicted by the media as a minnow compared to Google.</p>]]></content><author><name></name></author><category term="blog" /><category term="nlp" /><category term="llm" /><category term="openai" /><category term="chatgpt" /><category term="google" /><category term="microsoft" /><category term="python" /><summary type="html"><![CDATA[OpenAI's ChatGPT is a large language model designed to provide conversational AI services, but it is not yet a replacement for search engines.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/newspaper.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/newspaper.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Marketing Mix Modeling for Engineers</title><link href="https://victorangeloblancada.github.io/blog/2023/01/10/mmm-for-engineers.html" rel="alternate" type="text/html" title="Marketing Mix Modeling for Engineers" /><published>2023-01-10T00:00:00+08:00</published><updated>2023-01-10T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2023/01/10/mmm-for-engineers</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2023/01/10/mmm-for-engineers.html"><![CDATA[<p>Marketing Mix Modeling (MMM) is a powerful tool for understanding the effectiveness of a company’s marketing campaigns and strategies. Over the past decade, Python has become a popular choice for engineers and data scientists alike who are looking to develop and build MMM models. In this guide, we will discuss the fundamentals of marketing mix modeling and how to implement it using Python.</p>

<h2 id="data-collection">Data Collection</h2>

<p>The success of any MMM model is dependent on the data that is used to build it. It is important to collect the right data that will provide the insights and results needed. This includes data such as customer demographics, sales data, media spend, and other factors that could have an effect on the results. Once the data is gathered, it needs to be cleaned, organized, and prepared for analysis.</p>

<h2 id="selecting-features-for-the-regression-equation">Selecting Features for the Regression Equation</h2>

<p>When building a marketing mix model, the choice of features is critical for achieving accurate results. Here, we will focus on selecting the appropriate features for the regression equation.</p>

<h3 id="marketing-features">Marketing Features</h3>

<p>The most obvious starting point is to include all relevant marketing features. This includes, but is not limited to:</p>

<ul>
  <li>TV Spend</li>
  <li>Digital Impressions</li>
  <li>Print/Out of Home Advertising</li>
  <li>Social Media Metrics</li>
  <li>Other Promotional Activity</li>
</ul>

<h3 id="non-marketing-features">Non-Marketing Features</h3>

<p>In addition to marketing metrics, there are also non-marketing features that should be considered. These include:</p>

<ul>
  <li>Price of the Product</li>
  <li>Seasonality</li>
  <li>Competitor Activity</li>
</ul>

<h3 id="further-feature-engineering">Further Feature Engineering</h3>

<p>After selecting the features, further feature engineering may be necessary. This includes:</p>

<ul>
  <li>Normalizing Values</li>
  <li>Removing Outliers</li>
</ul>

<p>Using the right combination of features, marketing mix models can be incredibly powerful tools for understanding the impact of marketing activities on sales.</p>

<h2 id="model-building">Model Building</h2>

<p>Once the data is prepared, engineers can begin building the MMM model. This involves using Python’s various libraries such as Scikit-Learn and Pandas to build and test the model. The model should be tested multiple times to ensure that the results are accurate and reliable.</p>

<h2 id="mathematical-transformations">Mathematical Transformations</h2>

<p>Mathematical transformations are used in marketing mix modeling to analyze data and gain insights. Two of the most common transformations are decays or ad stocks and response curves. Both of these transformations are useful for gaining insights into the effectiveness of marketing campaigns.</p>

<h3 id="decays-or-ad-stocks">Decays or Ad Stocks</h3>

<p>Decays or ad stocks are a type of marketing tactic used to track and measure the decline in the effectiveness of a promotional campaign over a period of time. This decline, known as the decay rate, is evaluated to determine the rate at which the campaign’s influence wanes; this is important information for marketers, as it helps inform decisions as to when to refresh a campaign or create new ones. By monitoring the decay rate, marketers can ensure that their campaigns remain effective and that they are able to adjust their strategies accordingly.</p>

<h3 id="response-curves">Response Curves</h3>

<p>Response curves are a useful tool for marketers looking to understand the relationship between a marketing metric and sales. They can be used to estimate the impact of a marketing campaign by plotting the relationship between a metric and sales. Generally, sales response curves downward as diminishing returns set in. Plotting the response curve allows marketers to determine the potential impact of a campaign and adjust their strategy accordingly. It also helps them identify opportunities for improvement and inform decision-making around marketing strategies and investments.</p>

<h2 id="iterating-models">Iterating Models</h2>

<p>Analysts need to iterate through multiple possible marketing mix models to identify the equation that will provide the best estimate of the impact of marketing on sales. This process is usually achieved by performing a grid search across all potential models, based on a set of assumptions regarding the variables involved and the mathematical transformations that need to be applied.</p>

<p>The model with the highest accuracy – as measured using error metrics such as MSE, MAPE or coefficients of determination R2 – is often preferred. However, it is also important to ensure that the model’s coefficients make sense, and that the model is able to perform well, even when applied to data outside of the sample range. This prevents analysts from selecting models with nonsensical coefficients, such as an inverse relationship between media spending and sales.</p>

<h2 id="analysis-and-results">Analysis and Results</h2>

<p>Once the MMM model is built and tested, engineers can begin analyzing the results. The results should be compared to the objectives of the project and used to gain insights into the effectiveness of the marketing campaigns and strategies.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In conclusion, marketing mix modeling is a powerful tool for understanding the effectiveness of a company’s marketing campaigns and strategies. Python is a great choice for engineers and data scientists who are looking to build and test MMM models. With the right data, model building, and analysis, engineers can gain valuable insights into their marketing efforts.</p>]]></content><author><name></name></author><category term="blog" /><category term="ai" /><category term="ml" /><category term="artificial intelligence" /><category term="machine learning" /><category term="marketing" /><category term="marketing mix modeling" /><category term="python" /><summary type="html"><![CDATA[Marketing Mix Modeling (MMM) is a powerful tool for understanding the effectiveness of a company’s marketing campaigns and strategies.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/pointing.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/pointing.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Cropping an MS Teams Recording</title><link href="https://victorangeloblancada.github.io/blog/2022/12/07/teams-recording-resize.html" rel="alternate" type="text/html" title="Cropping an MS Teams Recording" /><published>2022-12-07T00:00:00+08:00</published><updated>2022-12-07T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2022/12/07/teams-recording-resize</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2022/12/07/teams-recording-resize.html"><![CDATA[<p><em>This is part of a series of short blog posts about automating <s>boring</s> repetitive work using Python.</em></p>

<p>Have you ever saved a recording of an MS Teams call where someone shared their screen and wanted to crop the recording to only keep the screen share? If so, you’re in luck.</p>

<p>This solution requires the <strong>ffmpeg</strong> library which I previously discussed as part of <a href="/blog/2019/09/20/command-line-gifs.html">a post covering creating GIFs from the command line</a>.</p>

<p>Running the following code in the command line automatically crops the MS Teams recording named “path_to_recording.mp4” and saves the output to “output.mp4”.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ffmpeg -i "path_to_recording.mp4" -filter:v "crop=1725:970:98:0" output.mp4
</code></pre></div></div>

<p>Before:</p>

<p><img src="/assets/images/Teams_Sample_Before.jpg" alt="Original recording" /></p>

<p>After:</p>

<p><img src="/assets/images/Teams_Sample_After.jpg" alt="Cropped recording" /></p>

<p>I do acknowledge that this solution depends on how MS Teams orients its interface and your screen resolution, but even if this changes, the general principle stays the same. You only need to alter the <code class="language-plaintext highlighter-rouge">crop=1725:970:98:0</code> part of the code. This section uses the following order of arguments: <code class="language-plaintext highlighter-rouge">crop=out_width:out_height:top_left_corner_x:top_left_corner_y</code>. So if you want to keep a video of width 1920 and height 1080 where the top left corner is at (0,0), the code would instead be:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ffmpeg -i "path_to_recording.mp4" -filter:v "crop=1920:1080:0:0" output.mp4
</code></pre></div></div>]]></content><author><name></name></author><category term="blog" /><category term="blog" /><category term="python" /><category term="video processing" /><category term="coding" /><category term="automation" /><summary type="html"><![CDATA[This is part of a series of short blog posts about automating boring repetitive work using Python.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/window.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/window.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">NaNoGenMo 2022</title><link href="https://victorangeloblancada.github.io/blog/2022/12/01/nanogenmo-2022.html" rel="alternate" type="text/html" title="NaNoGenMo 2022" /><published>2022-12-01T00:00:00+08:00</published><updated>2022-12-01T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2022/12/01/nanogenmo-2022</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2022/12/01/nanogenmo-2022.html"><![CDATA[<p>I participated in <a href="https://github.com/NaNoGenMo/2022">National Novel Generation Month for 2022</a>. This marked the third consecutive year where I completed my project.  <a href="https://github.com/victorangeloblancada/nanogenmo-2022">See here</a> for my GitHub repository with my code and my final novel.</p>

<p>With the recent breakthroughs in generative AI, I decided it was high time for me to use a Large Language Model (LLM) for a NaNoGenMo project. I opted to fine-tune a <a href="https://www.eleuther.ai/projects/gpt-neo/">GPT-Neo model</a> as I wanted control over the model itself lest the project turn into a prompt engineering exercise. I used <a href="https://github.com/minimaxir">Max Woolf</a>’s <a href="https://github.com/minimaxir/aitextgen">aitextgen</a> package to finetune the 125M GPT-Neo model on <a href="https://github.com/victorangeloblancada/nanogenmo-2022/tree/main/corpus">philosophy texts by Aristotle, Plato, Kant, Hume, and Nietzsche</a>. I used <a href="https://github.com/aparrish/pytracery">pytracery</a> to define grammars for model prompts.</p>

<p>Here are some brief, cherry-picked snippets from the output:</p>

<p><strong>What Will Happen If Literature Is Divine?</strong></p>

<blockquote>
  <p>What will happen if literature is divine?</p>

  <p>CLEINIAS: What do you mean? he said.</p>

  <p>ATHENIAN: I should say, that it must be the greatest of all things which can be known to us; and we ought not to seek for them in order that they may know what sort of things are better than words–and now let us have a way out of them.</p>

  <p>CLEINIAS: That would be my desire.</p>

  <p>ATHENIAN: But there is no difficulty in seeing how wisely Hesiod spoke when he says ‘the truth.’</p>

  <p>MEGILLUS: True.</p>
</blockquote>

<p><strong>What Is A Lover?</strong></p>

<blockquote>
  <p>What is a lover?</p>

  <p>Yes, he said.</p>

  <p>And what do you say of him who loves no one but himself? Would you not admit him to be loved by any one in whom there is no reason for praising or blaming others? For pity and hatred are opposites; they cannot be compared with each other when the latter becomes more innocent than the former.</p>
</blockquote>

<p><strong>What Is The Best Way To Be Joyful?</strong></p>

<blockquote>
  <p>What is the best way to be joyful?</p>

  <p>CLEINIAS: Certainly not, Stranger.</p>

  <p>ATHENIAN: And when you say that any one should abstain from weeping and lamenting in your sorrows utterances–whence do you admit this?</p>
</blockquote>

<p><em>Victor Blancada is a data scientist. Visit his LinkedIn page <a href="https://www.linkedin.com/in/geloblancada/">here</a>.</em></p>]]></content><author><name></name></author><category term="blog" /><category term="blog" /><category term="nlp" /><category term="nanogenmo" /><summary type="html"><![CDATA[I participated in National Novel Generation Month for 2022. This marked the third consecutive year where I completed my project. See here for my GitHub repository with my code and my final novel.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/DrunkPhilosophyCover.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/DrunkPhilosophyCover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Resize an Image to 4R</title><link href="https://victorangeloblancada.github.io/blog/2022/09/21/image-resize.html" rel="alternate" type="text/html" title="Resize an Image to 4R" /><published>2022-09-21T00:00:00+08:00</published><updated>2022-09-21T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2022/09/21/image-resize</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2022/09/21/image-resize.html"><![CDATA[<p><em>This is part of a series of short blog posts about automating <s>boring</s> repetitive work using Python.</em></p>

<p>The following code automatically resizes all images in the directory specified in <code class="language-plaintext highlighter-rouge">mypath</code> to 4R aspect ratio. 4R images have a size of 4 inches by 6 inches (or 10.2 cm by 15.2 cm), which means that images must have a 2 by 3 aspect ratio.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import libraries
</span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">listdir</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">join</span>

<span class="c1"># Directory containing the images
</span><span class="n">mypath</span> <span class="o">=</span> <span class="s">'Photos For Printing'</span>
<span class="n">d1</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># First dimension
</span><span class="n">d2</span> <span class="o">=</span> <span class="mi">6</span> <span class="c1"># Second dimension
</span>
<span class="c1"># Resize mode: Crop or extend with white space?
#mode = 'Crop'
</span><span class="n">mode</span> <span class="o">=</span> <span class="s">'Extend'</span>

<span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">listdir</span><span class="p">(</span><span class="n">mypath</span><span class="p">)</span> <span class="k">if</span> <span class="n">isfile</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">mypath</span><span class="p">,</span> <span class="n">f</span><span class="p">))]</span>

<span class="k">for</span> <span class="n">myfile</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
    <span class="c1"># Opens a image in RGB mode
</span>    <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">mypath</span><span class="o">+</span><span class="s">'/'</span><span class="o">+</span><span class="n">myfile</span><span class="p">)</span>

    <span class="c1"># Process image
</span>    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">'Crop'</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">&lt;</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">d1</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">d2</span>
            <span class="k">if</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">/</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">&gt;</span> <span class="n">d2</span> <span class="o">/</span> <span class="n">d1</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">*</span> <span class="n">d1</span> <span class="o">/</span> <span class="n">d2</span>
                <span class="c1"># Setting the points for cropped image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">top</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">right</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">m</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">*</span> <span class="n">d1</span> <span class="o">/</span> <span class="n">d2</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span>
                <span class="c1"># Setting the points for cropped image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">top</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">right</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">d2</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">d1</span>
            <span class="k">if</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">/</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">&gt;</span> <span class="n">d2</span> <span class="o">/</span> <span class="n">d1</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">*</span> <span class="n">d1</span> <span class="o">/</span> <span class="n">d2</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span>
                <span class="c1"># Setting the points for cropped image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">top</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">right</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">*</span> <span class="n">d1</span> <span class="o">/</span> <span class="n">d2</span>
                <span class="c1"># Setting the points for cropped image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">top</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">right</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">m</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">&lt;</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">d1</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">d2</span>
            <span class="k">if</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">/</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">&gt;</span> <span class="n">d2</span> <span class="o">/</span> <span class="n">d1</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">*</span> <span class="n">d1</span> <span class="o">/</span> <span class="n">d2</span>
                <span class="c1"># Setting the points for extended image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">top</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">right</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">*</span> <span class="n">d2</span> <span class="o">/</span> <span class="n">d1</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span>
                <span class="c1"># Setting the points for extended image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">top</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">right</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">d2</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">d1</span>
            <span class="k">if</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">/</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">&gt;</span> <span class="n">d2</span> <span class="o">/</span> <span class="n">d1</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">*</span> <span class="n">d1</span> <span class="o">/</span> <span class="n">d2</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span>
                <span class="c1"># Setting the points for extended image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">top</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">right</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span>         
            <span class="k">else</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span> <span class="o">*</span> <span class="n">d2</span> <span class="o">/</span> <span class="n">d1</span>
                <span class="c1"># Setting the points for extended image
</span>                <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">top</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>
                <span class="n">right</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">width</span>
                <span class="n">bottom</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">height</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span>

    <span class="c1"># Cropped image of above dimension
</span>    <span class="n">im1</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="s">'RGB'</span><span class="p">,</span> <span class="p">(</span><span class="n">right</span> <span class="o">-</span> <span class="n">left</span><span class="p">,</span> <span class="n">bottom</span> <span class="o">-</span> <span class="n">top</span><span class="p">),</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">))</span>
    <span class="n">im1</span><span class="p">.</span><span class="n">paste</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="n">left</span><span class="p">,</span> <span class="o">-</span><span class="n">top</span><span class="p">))</span>

    <span class="c1"># Save image
</span>    <span class="n">im1</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">mypath</span><span class="o">+</span><span class="s">'/'</span><span class="o">+</span><span class="n">myfile</span><span class="p">)</span>

</code></pre></div></div>]]></content><author><name></name></author><category term="blog" /><category term="blog" /><category term="python" /><category term="image processing" /><category term="coding" /><category term="automation" /><summary type="html"><![CDATA[This is part of a series of short blog posts about automating boring repetitive work using Python.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/frames.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/frames.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Adding a Date Watermark to an Image</title><link href="https://victorangeloblancada.github.io/blog/2022/09/20/image-watermark.html" rel="alternate" type="text/html" title="Adding a Date Watermark to an Image" /><published>2022-09-20T00:00:00+08:00</published><updated>2022-09-20T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2022/09/20/image-watermark</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2022/09/20/image-watermark.html"><![CDATA[<p><em>This is part of a series of short blog posts about automating <s>boring</s> repetitive work using Python.</em></p>

<p>The following code automatically adds a date watermark to all images in the directory specified in <code class="language-plaintext highlighter-rouge">mypath</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import libraries
</span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">ImageFont</span><span class="p">,</span> <span class="n">ImageDraw</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">listdir</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">join</span>

<span class="k">def</span> <span class="nf">get_date_taken</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="s">"""Function to get the date taken EXIF data.
    path: File path of image.
    """</span>
    <span class="k">return</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">).</span><span class="n">_getexif</span><span class="p">()[</span><span class="mi">36867</span><span class="p">]</span>

<span class="c1"># Specify directory
</span><span class="n">mypath</span> <span class="o">=</span> <span class="s">'Photos-001'</span>

<span class="c1"># Get list of files in the specified directory
</span><span class="n">onlyfiles</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">listdir</span><span class="p">(</span><span class="n">mypath</span><span class="p">)</span> <span class="k">if</span> <span class="n">isfile</span><span class="p">(</span><span class="n">join</span><span class="p">(</span><span class="n">mypath</span><span class="p">,</span> <span class="n">f</span><span class="p">))]</span>

<span class="c1"># Loop through list of files
</span><span class="k">for</span> <span class="n">image_fn</span> <span class="ow">in</span> <span class="n">onlyfiles</span><span class="p">:</span>
    <span class="c1"># Open image
</span>    <span class="n">watermark_image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">mypath</span><span class="o">+</span><span class="s">'/'</span><span class="o">+</span><span class="n">image_fn</span><span class="p">)</span> 

    <span class="c1"># Get image dimensions
</span>    <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">watermark_image</span><span class="p">.</span><span class="n">size</span>

    <span class="c1"># Initialize ImageDraw
</span>    <span class="n">draw</span> <span class="o">=</span> <span class="n">ImageDraw</span><span class="p">.</span><span class="n">Draw</span><span class="p">(</span><span class="n">watermark_image</span><span class="p">)</span>

    <span class="c1"># Set font size to around 3% of height (height divided by 33)
</span>    <span class="n">font</span> <span class="o">=</span> <span class="n">ImageFont</span><span class="p">.</span><span class="n">truetype</span><span class="p">(</span><span class="s">"arial.ttf"</span><span class="p">,</span> <span class="n">height</span><span class="o">//</span><span class="mi">33</span><span class="p">)</span>

    <span class="c1"># Add watermark
</span>    <span class="n">draw</span><span class="p">.</span><span class="n">text</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">height</span> <span class="o">-</span> <span class="p">(</span><span class="n">height</span><span class="o">//</span><span class="mi">33</span><span class="p">)),</span> 
              <span class="n">get_date_taken</span><span class="p">(</span><span class="n">mypath</span><span class="o">+</span><span class="s">'/'</span><span class="o">+</span><span class="n">image_fn</span><span class="p">),</span> 
              <span class="n">font</span><span class="o">=</span><span class="n">font</span><span class="p">,</span>
              <span class="n">fill</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">165</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">))</span>

    <span class="c1"># Save image
</span>    <span class="n">watermark_image</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">mypath</span><span class="o">+</span><span class="s">' Labeled/'</span><span class="o">+</span><span class="n">image_fn</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="blog" /><category term="blog" /><category term="python" /><category term="image processing" /><category term="coding" /><category term="automation" /><summary type="html"><![CDATA[This is part of a series of short blog posts about automating boring repetitive work using Python.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://victorangeloblancada.github.io/assets/images/prints.jpg" /><media:content medium="image" url="https://victorangeloblancada.github.io/assets/images/prints.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">State of the Art: Creativity in the Age of Stable Diffusion</title><link href="https://victorangeloblancada.github.io/blog/2022/09/06/state-of-the-art-creativity-in-the-age-of-stable-diffusion.html" rel="alternate" type="text/html" title="State of the Art: Creativity in the Age of Stable Diffusion" /><published>2022-09-06T00:00:00+08:00</published><updated>2022-09-06T00:00:00+08:00</updated><id>https://victorangeloblancada.github.io/blog/2022/09/06/state-of-the-art-creativity-in-the-age-of-stable-diffusion</id><content type="html" xml:base="https://victorangeloblancada.github.io/blog/2022/09/06/state-of-the-art-creativity-in-the-age-of-stable-diffusion.html"><![CDATA[<p><a href="https://www.smithsonianmag.com/smart-news/artificial-intelligence-art-wins-colorado-state-fair-180980703/">The first prize at the recently-held 2022 Colorado State Fair’s art competition in the digital category controversially went to a work created using Midjourney, an AI-powered text-to-image generator.</a> Artists were understandably upset but I would argue that society at large should welcome such a development.</p>

<p><img src="https://miro.medium.com/max/1400/0*t7Mv5hAMt_daMRml.jpg" alt="img" /></p>

<p>A number of people seem to think that using AI to produce art is tantamount to cheating because it supposedly devalues the human effort artists put into creating art, specifically the years and years spent honing their craft, <em>id est</em>, committing brush stroke technique to muscle memory, getting an almost instinctive intuition of color theory, <em>et cetera</em>. <a href="https://victorangeloblancada.github.io/blog/2019/03/25/democritization-of-expertise.html">As I have stated before, AI is so effective because machine learning models can simulate years of human practice into several hours of continuous training.</a> This means that given enough data and compute, AI will always eventually overtake humanity when it comes to reliably delivering perfect — nay superhuman — technique, including that which is used when it comes to crafting art.</p>

<blockquote>
  <p>The cutting edge is called state of the art for a reason.</p>
</blockquote>

<p>Given this fact, one possibility is to separate AI-augmented digital art from those that purely use what are considered standard (as of the time of this writing) tools such as digital artists’ favorite Adobe Photoshop, limited to a certain version. Ironically, nearly all software companies have been racing to incorporate AI into their products — <a href="https://www.makeuseof.com/what-is-adobe-sensei/">Adobe has touted Sensei’s artificial intelligence and machine learning models as an integral feature of Photoshop moving forward</a>, thereby making AI tools ubiquitous and requiring artists to use outdated versions of their software if they wish to to avoid AI altogether. By creating distinct categories based on how advanced the tools digital artists use are, we can ensure that artists compete on the same playing field. An AI classification model can be trained to differentiate between human-created digital art and image model outputs from Midjourney, Stable Diffusion, and DALL-E to enforce these categories.</p>

<p>More importantly though, there is much more to art than craft. Craft may involve putting in hours to develop technique, but it can be argued that taste — the ability to differentiate true art and envision such a project — is more valuable.</p>

<p>It is essential to note that Midjourney, along with other AI image generators in vogue such as Stable Diffusion and DALL-E, is a text-to-image model which means that users still need to specify text prompts. People do not simply press a button to create art, unlike how some people have been misinformed. Text-to-image models take in text prompts, such as “chiaroscuro masterpiece portrait of Steve Jobs by Caravaggio”, and require tuning certain parameters such as a guidance scale to generate an image based on the prompt.</p>

<p><img src="https://miro.medium.com/max/1400/1*74sVNvrV7JBkDG3PpdGzfg.jpeg" alt="img" /></p>

<p>Today’s state of the art text-to-image AI models use a neural network architecture to convert text inputs to images. This line of research originated from image captioning models, which take images inputs and generate appropriate descriptive captions. Computer scientists then attempted to build a model that can do the reverse — a model that can take in descriptive text inputs and output the appropriate image. While image search algorithms on search engines such as Google use keywords to select appropriate images from a universe of existing images on the Internet based on something like a similarity score, text-to-image models instead start with an image of random noise and algorithmically modify it to generate the image that maximizes its similarity to the provided text prompt. The datasets used in training these models, such as Stable Diffusion’s <a href="https://laion.ai/blog/laion-5b/">LAION-5B dataset</a>, comes from image-text-pairs scraped from the Internet, leading to idiosyncrasies such as celebrity social media handles working as stand-ins for their actual names.</p>

<p><img src="https://miro.medium.com/max/1400/0*B9dfrkAzCYBY-Gi_" alt="img" /></p>

<p>Crafting text prompts is therefore a science and an art(!) unto itself —<a href="https://paperswithcode.com/task/prompt-engineering"> there are numerous scientific papers published on the nuances of prompt engineering.</a></p>

<p>Given this, artists who use text-to-image models such as Midjourney still have an active role to play in creating art.<a href="https://victorangeloblancada.github.io/blog/2019/03/25/democritization-of-expertise.html"> As I have written previously, corporate workers of tomorrow must take on more of a managerial mindset as AI automates an increasing number of mundane operational tasks.</a> The same is true in art: the artists of tomorrow must take on more of an editorial mindset and guide AI as it takes care of tasks requiring craft and technique.</p>

<p>Many of history’s most celebrated artists — from Picasso to Duchamp to Warhol — have embraced the idea of <a href="https://www.moma.org/learn/moma_learning/themes/dada/marcel-duchamp-and-the-readymade/">found art</a>. For the uninitiated, found art, also known as found objects or ready-mades, are existing objects that are selected by artists and are recognized as art by merit of having been identified as art by an artist. Found art does not have to be crafted by an artist; instead, the artist’s contribution comes from possessing the tasteful eye to identify found art as art. Found art is an exceptional case of art emerging from taste rather than craft. AI-generated art is not as extreme as found art — users still need to craft text prompts and refine model parameters — but is just as valid as art.</p>

<p>The great artist Michaelangelo said it best: “Every block of stone has a statue inside it and it is the task of the sculptor to discover it.” In the olden days, this required artists to hone their technique in the use of tools such as chisels and brushes. As recently as two decades ago, computers have turned these tools digital as artists began using software such as Photoshop and Blender. It should therefore come as no surprise that artists today use AI-powered tools to produce award-winning artwork. The cutting edge is called state of the art for a reason.</p>

<p>Of course, given sufficient data points (art and their judged scores) from competitions, we can always just build an AI model that creates the optimal artwork to win a competition, but this just replaces the human input away from text prompts to judges’ scores. This then would be the state of the art of found art, until the next advancement comes along.</p>

<p><em>This article was also posted on <a href="https://medium.com/@gelo.blancada/state-of-the-art-creativity-in-the-age-of-stable-diffusion-407bd2b98776">Medium</a>.</em></p>]]></content><author><name></name></author><category term="blog" /><category term="blog" /><category term="ai" /><category term="artificial intelligence" /><category term="art" /><category term="creativity" /><category term="machine learning" /><category term="opinion" /><summary type="html"><![CDATA[The first prize at the recently-held 2022 Colorado State Fair’s art competition in the digital category controversially went to a work created using Midjourney, an AI-powered text-to-image generator. Artists were understandably upset but I would argue that society at large should welcome such a development.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://miro.medium.com/max/1400/1*OMKOu2adjb0WjYEej9ap3A.jpeg" /><media:content medium="image" url="https://miro.medium.com/max/1400/1*OMKOu2adjb0WjYEej9ap3A.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>